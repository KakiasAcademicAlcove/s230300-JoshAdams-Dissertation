version: "3.8"

volumes:
  certs:
    name: certs
    driver: local
  freeradius_logs:
    name: freeradius_logs
    driver: local
  freeradius_data:
    name: freeradius_data
    driver: local
  kafka_1_data:
    name: kafka_1_data
    driver: local
  kafka_2_data:
    name: kafka_2_data
    driver: local
  kafka_3_data:
    name: kafka_3_data
    driver: local
  elasticsearch_data:
    name: elasticsearch_data
    driver: local
  kibana_data:
    name: kibana_data
    driver: local
  logstash_data:
    name: logstash_data
    driver: local
  metricbeat_data:
    name: metricbeat_data
    driver: local
  filebeat_data:
    name: filebeat_data
    driver: local

networks:
  kafka_network:
    name: kafka_network
    driver: bridge
  elastic_network:
    name: elastic_network
    driver: bridge

services:
  elastic-certs:
   image: docker.elastic.co/elasticsearch/elasticsearch:${ELASTIC_VERSION}
   container_name: elastic-certs
   environment:
    - ELASTIC_USER=elastic
    - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
    - KIBANA_PASSWORD=${KIBANA_PASSWORD}
   volumes:
     - certs:/usr/share/elasticsearch/config/certs
     - ./certs/elastic:/elastic_certs_setup
   networks:
    - elastic_network
   user: "0"
   entrypoint: ["/bin/bash", "-c"]
   command: >
      "
      chmod +x /elastic_certs_setup/certs_creation.sh &&
      /elastic_certs_setup/certs_creation.sh
      "
   healthcheck:
     test: ["CMD-SHELL", "[ -f config/certs/elasticsearch/elasticsearch.crt ]"]
     interval: 1s
     timeout: 5s
     retries: 120

  elasticsearch:
   depends_on:
      elastic-certs:
       condition: service_healthy
   image: docker.elastic.co/elasticsearch/elasticsearch:${ELASTIC_VERSION}
   container_name: elasticsearch
   labels:
     co.elastic.logs/module: elasticsearch
   volumes:
     - certs:/usr/share/elasticsearch/config/certs
     - elasticsearch_data:/usr/share/elasticsearch/data
   ports:
     - ${ELASTICSEARCH_PORT}:9200
   networks:
    - elastic_network
   environment:
     - node.name=elasticsearch
     - cluster.name=${ELASTICSEARCH_CLUSTER_NAME}
     - discovery.type=single-node
     - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
     - bootstrap.memory_lock=true
     - xpack.security.enabled=true
     - xpack.security.http.ssl.enabled=true
     - xpack.security.http.ssl.key=certs/elasticsearch/elasticsearch.key
     - xpack.security.http.ssl.certificate=certs/elasticsearch/elasticsearch.crt
     - xpack.security.http.ssl.certificate_authorities=certs/ca/ca.crt
     - xpack.security.transport.ssl.enabled=true
     - xpack.security.transport.ssl.key=certs/elasticsearch/elasticsearch.key
     - xpack.security.transport.ssl.certificate=certs/elasticsearch/elasticsearch.crt
     - xpack.security.transport.ssl.certificate_authorities=certs/ca/ca.crt
     - xpack.security.transport.ssl.verification_mode=certificate
     - xpack.license.self_generated.type=${ELASTICSEARCH_LICENSE}
   mem_limit: ${ELASTICSEARCH_MEMORY_LIMIT}
   ulimits:
     memlock:
       soft: -1
       hard: -1
   healthcheck:
     test:
       [
         "CMD-SHELL",
         "curl -s --cacert config/certs/ca/ca.crt https://localhost:9200 | grep -q 'missing authentication credentials'",
       ]
     interval: 10s
     timeout: 10s
     retries: 120

  kibana:
   depends_on:
     elasticsearch:
       condition: service_healthy
   image: docker.elastic.co/kibana/kibana:${ELASTIC_VERSION}
   container_name: kibana
   labels:
     co.elastic.logs/module: kibana
   volumes:
     - certs:/usr/share/kibana/config/certs
     - kibana_data:/usr/share/kibana/data
   ports:
     - ${KIBANA_PORT}:5601
   environment:
     - SERVERNAME=kibana
     - ELASTICSEARCH_HOSTS=https://elasticsearch:9200
     - ELASTICSEARCH_USERNAME=kibana_system
     - ELASTICSEARCH_PASSWORD=${KIBANA_PASSWORD}
     - ELASTICSEARCH_SSL_CERTIFICATEAUTHORITIES=config/certs/ca/ca.crt
     - XPACK_SECURITY_ENCRYPTIONKEY=${ELASTIC_ENCRYPTION_KEY}
     - XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY=${ELASTIC_ENCRYPTION_KEY}
     - XPACK_REPORTING_ENCRYPTIONKEY=${ELASTIC_ENCRYPTION_KEY}
   networks:
    - elastic_network
   mem_limit: ${KIBANA_MEMORY_LIMIT}
   healthcheck:
    test:
      [
        "CMD-SHELL",
        "curl -s -I http://localhost:5601 | grep -q 'HTTP/1.1 302 Found'",
      ]
    interval: 10s
    timeout: 10s
    retries: 120

  kafka-1:
    image: apache/kafka:${KAFKA_VERSION}
    container_name: kafka-1
    environment:
      KAFKA_NODE_ID: ${KAFKA_NODE_1_NODE_ID}
      KAFKA_PROCESS_ROLES: ${KAFKA_NODE_1_PROCESS_ROLES}
      KAFKA_LISTENERS: ${KAFKA_NODE_1_LISTENERS}
      KAFKA_ADVERTISED_LISTENERS: ${KAFKA_NODE_1_ADVERTISED_LISTENERS}
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: ${KAFKA_NODE_1_LISTENER_SECURITY_PROTOCOL_MAP}
      KAFKA_CONTROLLER_LISTENER_NAMES: ${KAFKA_NODE_1_CONTROLLER_LISTENER_NAMES}
      KAFKA_INTER_BROKER_LISTENER_NAME: ${KAFKA_NODE_1_INTER_BROKER_LISTENER_NAME}
      KAFKA_CONTROLLER_QUORUM_VOTERS: ${KAFKA_NODE_1_CONTROLLER_QUORUM_VOTERS}
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: ${KAFKA_NODE_1_GROUP_INITIAL_REBALANCE_DELAY_MS}
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: ${KAFKA_NODE_1_AUTO_CREATE_TOPICS_ENABLE}
      KAFKA_NUM_PARTITIONS: ${KAFKA_NODE_1_NUM_PARTITIONS}
      KAFKA_MIN_INSYNC_REPLICAS: ${KAFKA_NODE_1_MIN_INSYNC_REPLICAS}
      KAFKA_DEFAULT_REPLICATION_FACTOR: ${KAFKA_NODE_1_DEFAULT_REPLICATION_FACTOR}
      KAFKA_LOG_RETENTION_HOURS: ${KAFKA_NODE_1_LOG_RETENTION_HOURS}
      KAFKA_MESSAGE_MAX_BYTES: ${KAFKA_NODE_1_MESSAGE_MAX_BYTES}
    ports:
      - "19092:9092"
    volumes:
      - kafka_1_data:/var/lib/kafka
      - ${KAFKA_NODE_1_CONFIG_DIR}/server.properties:/opt/kafka/config/server.properties
    networks:
      - kafka_network
      - elastic_network
    mem_limit: ${KAFKA_MEMORY_LIMIT}
    healthcheck:
      test: /opt/kafka/bin/kafka-cluster.sh cluster-id --bootstrap-server kafka-1:9092 || exit 1
      interval: 10s
      timeout: 10s
      retries: 120

  kafka-2:
    image: apache/kafka:${KAFKA_VERSION}
    container_name: kafka-2
    environment:
      KAFKA_NODE_ID: ${KAFKA_NODE_2_NODE_ID}
      KAFKA_PROCESS_ROLES: ${KAFKA_NODE_2_PROCESS_ROLES}
      KAFKA_LISTENERS: ${KAFKA_NODE_2_LISTENERS}
      KAFKA_ADVERTISED_LISTENERS: ${KAFKA_NODE_2_ADVERTISED_LISTENERS}
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: ${KAFKA_NODE_2_LISTENER_SECURITY_PROTOCOL_MAP}
      KAFKA_CONTROLLER_LISTENER_NAMES: ${KAFKA_NODE_2_CONTROLLER_LISTENER_NAMES}
      KAFKA_INTER_BROKER_LISTENER_NAME: ${KAFKA_NODE_2_INTER_BROKER_LISTENER_NAME}
      KAFKA_CONTROLLER_QUORUM_VOTERS: ${KAFKA_NODE_2_CONTROLLER_QUORUM_VOTERS}
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: ${KAFKA_NODE_2_GROUP_INITIAL_REBALANCE_DELAY_MS}
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: ${KAFKA_NODE_2_AUTO_CREATE_TOPICS_ENABLE}
      KAFKA_NUM_PARTITIONS: ${KAFKA_NODE_2_NUM_PARTITIONS}
      KAFKA_MIN_INSYNC_REPLICAS: ${KAFKA_NODE_2_MIN_INSYNC_REPLICAS}
      KAFKA_DEFAULT_REPLICATION_FACTOR: ${KAFKA_NODE_2_DEFAULT_REPLICATION_FACTOR}
      KAFKA_LOG_RETENTION_HOURS: ${KAFKA_NODE_2_LOG_RETENTION_HOURS}
      KAFKA_MESSAGE_MAX_BYTES: ${KAFKA_NODE_2_MESSAGE_MAX_BYTES}
    ports:
      - "29092:9092"
    volumes:
      - kafka_2_data:/var/lib/kafka
      - ${KAFKA_NODE_2_CONFIG_DIR}/server.properties:/opt/kafka/config/server.properties
    networks:
      - kafka_network
      - elastic_network
    mem_limit: ${KAFKA_MEMORY_LIMIT}
    healthcheck:
      test: /opt/kafka/bin/kafka-cluster.sh cluster-id --bootstrap-server kafka-2:9092 || exit 1
      interval: 10s
      timeout: 10s
      retries: 120
  
  kafka-3:
    image: apache/kafka:${KAFKA_VERSION}
    container_name: kafka-3
    environment:
      KAFKA_NODE_ID: ${KAFKA_NODE_3_NODE_ID}
      KAFKA_PROCESS_ROLES: ${KAFKA_NODE_3_PROCESS_ROLES}
      KAFKA_LISTENERS: ${KAFKA_NODE_3_LISTENERS}
      KAFKA_ADVERTISED_LISTENERS: ${KAFKA_NODE_3_ADVERTISED_LISTENERS}
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: ${KAFKA_NODE_3_LISTENER_SECURITY_PROTOCOL_MAP}
      KAFKA_CONTROLLER_LISTENER_NAMES: ${KAFKA_NODE_3_CONTROLLER_LISTENER_NAMES}
      KAFKA_INTER_BROKER_LISTENER_NAME: ${KAFKA_NODE_3_INTER_BROKER_LISTENER_NAME}
      KAFKA_CONTROLLER_QUORUM_VOTERS: ${KAFKA_NODE_3_CONTROLLER_QUORUM_VOTERS}
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: ${KAFKA_NODE_3_GROUP_INITIAL_REBALANCE_DELAY_MS}
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: ${KAFKA_NODE_3_AUTO_CREATE_TOPICS_ENABLE}
      KAFKA_NUM_PARTITIONS: ${KAFKA_NODE_3_NUM_PARTITIONS}
      KAFKA_MIN_INSYNC_REPLICAS: ${KAFKA_NODE_3_MIN_INSYNC_REPLICAS}
      KAFKA_DEFAULT_REPLICATION_FACTOR: ${KAFKA_NODE_3_DEFAULT_REPLICATION_FACTOR}
      KAFKA_LOG_RETENTION_HOURS: ${KAFKA_NODE_3_LOG_RETENTION_HOURS}
      KAFKA_MESSAGE_MAX_BYTES: ${KAFKA_NODE_3_MESSAGE_MAX_BYTES}
    ports:
      - "39092:9092"
    volumes:
      - kafka_3_data:/var/lib/kafka
      - ${KAFKA_NODE_3_CONFIG_DIR}/server.properties:/opt/kafka/config/server.properties
    networks:
      - kafka_network
      - elastic_network
    mem_limit: ${KAFKA_MEMORY_LIMIT}
    healthcheck:
      test: /opt/kafka/bin/kafka-cluster.sh cluster-id --bootstrap-server kafka-3:9092 || exit 1
      interval: 10s
      timeout: 10s
      retries: 120

  kibana-setup:
    image: curlimages/curl:${CURL_VERSION}
    container_name: kibana-setup
    user: root
    environment:
      - ELASTICSEARCH_URL=https://elasticsearch:9200
      - KIBANA_URL=${KIBANA_HOST}
      - ELASTIC_USER=elastic
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - KIBANA_SUPERUSER=super_kibana
      - KIBANA_SUPERUSER_PASSWORD=${KIBANA_SUPERUSER_PASSWORD}
      - SSL_ENABLED=true
    volumes:
      - certs:/certs
      - ./services/kibana/setup:/kibana_setup
    entrypoint: ["/bin/sh", "-c"]
    command: >
      "
      apk add --no-cache bash &&
      chmod +x /kibana_setup/import_saved_objects.sh &&
      /kibana_setup/import_saved_objects.sh
      "
    depends_on:
      kibana:
        condition: service_healthy
    networks:
      - elastic_network
    # profiles:
    #   - setup

  logstash:
    depends_on:
      elasticsearch:
        condition: service_healthy
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
    # build: ./services/logstash
    image: docker.elastic.co/logstash/logstash:${ELASTIC_VERSION}
    container_name: logstash
    user: root 
    labels:
      co.elastic.logs/module: logstash
    volumes:
      - certs:/usr/share/logstash/certs
      - freeradius_logs:${FREERADIUS_LOG_DIR}:ro
      - "./services/logstash/ingest_data/:/usr/share/logstash/ingest_data/"
      - "./services/logstash/pipeline/ssl/freeradius_acct_to_es.conf:/usr/share/logstash/pipeline/freeradius_acct_to_es.conf:ro"
      - "./services/logstash/pipeline/ssl/freeradius_acct_to_kafka.conf:/usr/share/logstash/pipeline/freeradius_acct_to_kafka.conf:ro"
      - "./services/logstash/pipeline/ssl/freeradius_auth_accept_to_kafka.conf:/usr/share/logstash/pipeline/freeradius_auth_accept_to_kafka.conf:ro"
      - "./services/logstash/pipeline/ssl/freeradius_auth_reject_to_kafka.conf:/usr/share/logstash/pipeline/freeradius_auth_reject_to_kafka.conf:ro"
      - "./services/logstash/pipeline/ssl/freeradius_auth_to_es.conf:/usr/share/logstash/pipeline/freeradius_auth_to_es.conf:ro"
      - "./services/logstash/config/pipelines.yml:/usr/share/logstash/config/pipelines.yml:ro"
      # - "./services/logstash/config:/usr/share/logstash/config"
      # - logstash_config:/usr/share/logstash/config
    environment:
      - xpack.monitoring.enabled=false
      - ELASTIC_USER=elastic
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - ELASTIC_HOSTS=https://elasticsearch:9200
    ports:
      - "${LOGSTASH_PORT}:5044"
    networks:
      - kafka_network
      - elastic_network
    healthcheck:
      test: curl -fs http://localhost:9600 || exit 1
      interval: 10s
      timeout: 10s
      retries: 120

  metricbeat:
    container_name: metricbeat
    depends_on:
      elasticsearch:
        condition: service_healthy
    image: docker.elastic.co/beats/metricbeat:${ELASTIC_VERSION}
    user: root
    volumes:
      - certs:/usr/share/metricbeat/certs
      - metricbeat_data:/usr/share/metricbeat/data
      - "./services/metricbeat/config/metricbeat.yml:/usr/share/metricbeat/metricbeat.yml:ro"
      - "/var/run/docker.sock:/var/run/docker.sock:ro"
      - "/sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro"
      - "/proc:/hostfs/proc:ro"
      - "/:/hostfs:ro"
    environment:
      - ELASTIC_USER=elastic
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - ELASTIC_HOSTS=https://elasticsearch:9200
      - KIBANA_HOSTS=${KIBANA_HOST}
      - LOGSTASH_HOSTS=${LOGSTASH_HOST}
    networks:
      - elastic_network

  filebeat:
    container_name: filebeat
    depends_on:
      elasticsearch:
        condition: service_healthy
    image: docker.elastic.co/beats/filebeat:${ELASTIC_VERSION}
    user: root
    volumes:
      - certs:/usr/share/filebeat/certs
      - filebeat_data:/usr/share/filebeat/data
      - "./services/filebeat/ingest_data/:/usr/share/filebeat/ingest_data/"
      - "./services/filebeat/config/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro"
      - "/var/lib/docker/containers:/var/lib/docker/containers:ro"
      - "/var/run/docker.sock:/var/run/docker.sock:ro"
    environment:
      - ELASTIC_USER=elastic
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - ELASTIC_HOSTS=https://elasticsearch:9200
      - KIBANA_HOSTS=${KIBANA_HOST}
      - LOGSTASH_HOSTS=${LOGSTASH_HOST}
    networks:
      - elastic_network

  freeradius:
    build: ./services/freeradius
    container_name: freeradius
    volumes:
      - freeradius_logs:${FREERADIUS_LOG_DIR}
      - type: bind
        source: ${FREERADIUS_CONFIG_DIR}/radiusd.conf
        target: /etc/freeradius/radiusd.conf
      - type: bind
        source: ${FREERADIUS_CONFIG_DIR}/users
        target: /etc/freeradius/users
      - type: bind
        source: ${FREERADIUS_CONFIG_DIR}/mods-available/detail
        target: /etc/freeradius/mods-available/detail
    entrypoint: ["freeradius", "-f"]
    ports:
      - "1812:1812/udp"
      - "1813:1813/udp"
    networks:
      - kafka_network
    depends_on:
      logstash:
        condition:
          service_healthy
